{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail = pd.read_csv('new_spam.csv', index_col = 0)\n",
    "\n",
    "mail.dropna(axis=0, inplace=True)\n",
    "\n",
    "mail = mail.replace('spam', 1)\n",
    "mail = mail.replace('ham', 0)\n",
    "mail['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19964 entries, 1 to 20100\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      19964 non-null  object\n",
      " 1   label     19964 non-null  int64 \n",
      " 2   new_text  19964 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 623.9+ KB\n"
     ]
    }
   ],
   "source": [
    "mail.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = mail['text']\n",
    "y_data = mail['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 7000\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_data) # 토큰화\n",
    "sequences = tokenizer.texts_to_sequences(X_data) # 토큰에 인덱스 추가\n",
    "X_data = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19964, 110)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 110\n",
    "X_data = pad_sequences(X_data, maxlen = max_len)\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 모델 구축\n",
    "# 레이어들을 쌓을 모델을 생성\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "999/999 [==============================] - 9s 7ms/step - loss: 0.3804 - acc: 0.8108 - val_loss: 0.2746 - val_acc: 0.8835\n",
      "Epoch 2/10\n",
      "999/999 [==============================] - 7s 7ms/step - loss: 0.2130 - acc: 0.8994 - val_loss: 0.2176 - val_acc: 0.8933\n",
      "Epoch 3/10\n",
      "999/999 [==============================] - 7s 7ms/step - loss: 0.1808 - acc: 0.9095 - val_loss: 0.2215 - val_acc: 0.8961\n",
      "Epoch 4/10\n",
      "999/999 [==============================] - 7s 7ms/step - loss: 0.1703 - acc: 0.9137 - val_loss: 0.2278 - val_acc: 0.8888\n",
      "Epoch 5/10\n",
      "999/999 [==============================] - 7s 7ms/step - loss: 0.1631 - acc: 0.9151 - val_loss: 0.2362 - val_acc: 0.8891\n",
      "Epoch 00005: early stopping\n",
      "35.098921060562134\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t1 = time()\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=16, callbacks = [es])\n",
    "t2 = time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.read_csv(\"spam_test_text.csv\", encoding = 'utf-8')\n",
    "test_label = pd.read_csv(\"spam_test_label.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9896, 110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.texts_to_sequences(test_text['text'])\n",
    "test = pad_sequences(test, maxlen = max_len)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in pred:\n",
    "    if i > 0.5:\n",
    "        labels.append('spam')\n",
    "    else:\n",
    "        labels.append('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.939682  0.738586  0.827086      4556\n",
      "        spam   0.811401  0.959551  0.879279      5340\n",
      "\n",
      "    accuracy                       0.857821      9896\n",
      "   macro avg   0.875542  0.849069  0.853183      9896\n",
      "weighted avg   0.870460  0.857821  0.855250      9896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "print(classification_report(labels, test_label['label'], digits = 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
